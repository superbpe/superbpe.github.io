<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZDNTVNBZY9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-ZDNTVNBZY9');
  </script>

  <meta charset="utf-8">
  <meta name="description"
        content="SuperBPE: Space Travel for Language Models">
  <meta name="keywords" content="superbpe superword tokenization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SuperBPE: Space Travel for Language Models</title>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Mono:wght@100..900&family=Noto+Sans:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@iframe-resizer/parent@5.3.3"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
</head>
<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SuperBPE: Space Travel for Language Models</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">*<a href="https://alisawuffles.github.io/">Alisa Liu</a><sup>&hearts;&#65038;&spades;&#65038;</sup>,</span>
            <span class="author-block">*<a href="https://jon.jon.ke/">Jonathan Hayase</a><sup>&hearts;&#65038;</sup>,</span>
            <span class="author-block"><a href="https://valentinhofmann.github.io/">Valentin Hofmann</a><sup>&diams;&#65038;&hearts;&#65038;</sup>,</span>
            <span class="author-block"><a href="https://homes.cs.washington.edu/~sewoong/">Sewoong Oh</a><sup>&hearts;&#65038;</sup>,</span>
            <span class="author-block"><a href="https://nasmith.github.io/">Noah A. Smith</a><sup>&hearts;&#65038;&diams;&#65038;</sup>,</span>
            <span class="author-block"><a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a><sup>&spades;&#65038;</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>&hearts;&#65038;</sup>University of Washington,</span>
            <span class="author-block"><sup>&spades;&#65038;</sup>NVIDIA</span>,
            <span class="author-block"><sup>&diams;&#65038;</sup>Allen Institute for AI</span>,
            <span class="eql-cntrb">*Equal contribution</span>
          </div>
        </div>
      </div>
      
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <span class="link-block">
              <a href="https://arxiv.org/pdf/2503.13423" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://arxiv.org/abs/2503.13423" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                <span>arXiv</span>
              </a>
            </span>
            <!-- Code Link. -->
            <span class="link-block">
              <a href="coming-soon.txt" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://huggingface.co/collections/UW/superbpe-67db2338062faa07c7473ffa" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-cloud-download-alt"></i></span>
                <span>HuggingFace</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="tldr">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths">
          <!-- TL;DR Section -->
        <div class="content is-size-5">
          <em><strong>TL;DR:</strong> We introduce a family of superword tokenizers which encode the same text using, on average, up to 33% fewer tokens than a BPE tokenizer of the same size. Models trained with our tokenizer are more efficient during inference while also outperforming the baseline by +4.0% on average over a suite of 30 downstream tasks, including +8.2% on MMLU.</em>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="playground">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="content">
          <iframe src="https://jhayase-superbpe-tokenizer-playground.static.hf.space"
                  frameborder="0"
            width="100%"
            id="playgroundframe"></iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="intro">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths">
        <div class="content">
          <p>
            Tokenizers are the interface through which language models interact with the world. Beginning from a blank slate, they learn the shape and form of language as sequences of tokens. Each token is a segment of text that belongs in the language model’s “vocabulary,” and the language model learns to predict the next-token given the current context.
          </p>
          <p>
            In the era of transformer language models, tokenization is done at the level of subwords, meaning that tokens are <em>parts</em> of words (including complete words), but cannot bridge whitespace. Historically, subword tokenization was meant to combine the strengths of <em>word-level tokenization</em>, which cannot easily handle novel words, and <em>byte-level tokenization</em>, which can represent arbitrary text but is much less efficient.
          </p>
          <p>
            But for modern language models, does it really make sense to limit tokens to parts of words? Whitespace is not a consistent delimiter of meaning — multi-word expressions (<em>“by the way”</em>) function semantically as single units, and different languages vary in the number of words needed to express a concept (<em>“spacesuit helmet”</em> is <em>“Raumanzughelm”</em> in German). At the extreme, <strong>languages such as Chinese do not use whitespace at all</strong>. Tokens in these languages span multiple words and even <a href="https://x.com/suchenzang/status/1790171161512587424">entire sentences</a>, yet this has seemingly not hindered LMs from learning these languages.
          </p>
          <p>
            To explore the potential of tokenization beyond subwords, we introduce <strong>SuperBPE</strong>, an algorithm that produces a tokenizer including both subword and “superword” tokens. SuperBPE dramatically improves encoding efficiency over BPE, meaning that it consistently segments the same piece of text into fewer tokens. This is because while BPE tokenizers quickly exhaust the set of “useful” words to add to the vocabulary, SuperBPE can continue to discover common word sequences to treat as single tokens. For instance, at a fixed vocabulary size of 200k, a SuperBPE tokenizer uses ⅓ fewer tokens than BPE to encode the same amount of text!
          </p>
          <iframe id="plotframe" src="static/images/test.html"
                  frameborder="0"
                  width="100%" scrolling="no"></iframe>
          <p>
            What happens when we train models with superword tokenizers? In our experiments, we pretrain 8B models from scratch, fixing everything about the model architecture and training setup and varying only the algorithm for learning the vocabulary. We find that <strong>models trained with SuperBPE tokenizers are consistently better</strong> — our best model achieves a <strong>+4.0% absolute improvement on average over 30 downstream tasks</strong> over the BPE baseline, winning on 25/30 of the individual tasks (including +8.2% on MMLU), <strong>while also being 27% more efficient at inference time.</strong>
          </p>
          <p>
          <table class="table is-hoverable is-size-7" id="resulttab">
            <thead>
              <tr>
                <th>Category</th>
                <th>Task</th>
                <th>BPE</th>
                <th>SuperBPE</th>
                <th>&Delta;</th>
              </tr>
            </thead>
            <tbody>
              <tr class="hruled">
                <td>Knowledge</td>
                <td>ARC-Easy <small>(MC)</small></td>
                <td>46.6</td>
                <td><strong>67.1</strong></td>
                <td>+20.5</td>
              </tr>
              <tr>
                <td></td>
                <td>ARC-Challenge <small>(MC)</small></td>
                <td>35.1</td>
                <td><strong>50.6</strong></td>
                <td>+15.5</td>
              </tr>
              <tr>
                <td></td>
                <td>Jeopardy <small>(MC)</small></td>
                <td><strong>42.1</strong></td>
                <td>41.8</td>
                <td>&minus;0.3</td>
              </tr>
              <tr>
                <td></td>
                <td>MMLU <small>(MC)</small></td>
                <td>36.5</td>
                <td><strong>44.7</strong></td>
                <td>+8.2</td>
              </tr>
              <tr>
                <td></td>
                <td>OpenbookQA <small>(MC)</small></td>
                <td>33.2</td>
                <td><strong>54.4</strong></td>
                <td>+21.2</td>
              </tr>
              <tr>
                <td></td>
                <td>TriviaQA <small>(EM)</small></td>
                <td>60.6</td>
                <td><strong>61.3</strong></td>
                <td>+0.7</td>
              </tr>
              <tr>
                <td></td>
                <td>WikidataQA <small>(EM)</small></td>
                <td>69.7</td>
                <td><strong>70.9</strong></td>
                <td>+1.2</td>
              </tr>
              <tr class="hruled">
                <td>Math &amp; Reasoning</td>
                <td>Arithmetic <small>(EM)</small></td>
                <td>54.8</td>
                <td><strong>59.3</strong></td>
                <td>+4.5</td>
              </tr>
              <tr>
                <td></td>
                <td>GSM8K <small>(EM)</small></td>
                <td>6.4</td>
                <td><strong>6.7</strong></td>
                <td>+0.3</td>
              </tr>
              <tr>
                <td></td>
                <td>LSAT-AR <small>(MC)</small></td>
                <td>21.3</td>
                <td><strong>23.0</strong></td>
                <td>+1.7</td>
              </tr>
              <tr>
                <td></td>
                <td>Operators <small>(EM)</small></td>
                <td><strong>35.5</strong></td>
                <td>33.6</td>
                <td>&minus;1.9</td>
              </tr>
              <tr>
                <td></td>
                <td>Repeat-Copy-Logic <small>(EM)</small></td>
                <td>3.1</td>
                <td><strong>6.2</strong></td>
                <td>+3.1</td>
              </tr>
              <tr class="hruled">
                <td>Coding</td>
                <td>HumanEval <small>(pass@10)</small></td>
                <td><strong>15.9</strong></td>
                <td>13.4</td>
                <td>&minus;2.5</td>
              </tr>
              <tr>
                <td></td>
                <td>MBPP <small>(pass@10)</small></td>
                <td>27.5</td>
                <td><strong>28.3</strong></td>
                <td>+0.8</td>
              </tr>
              <tr class="hruled">
                <td>Reading Comprehension</td>
                <td>BoolQ <small>(MC)</small></td>
                <td>59.7</td>
                <td><strong>64.6</strong></td>
                <td>+4.9</td>
              </tr>
              <tr>
                <td></td>
                <td>CoQA <small>(EM)</small></td>
                <td>12.6</td>
                <td><strong>13.2</strong></td>
                <td>+0.6</td>
              </tr>
              <tr>
                <td></td>
                <td>DROP <small>(EM)</small></td>
                <td>31.3</td>
                <td><strong>31.4</strong></td>
                <td>+0.1</td>
              </tr>
              <tr>
                <td></td>
                <td>HotpotQA <small>(EM)</small></td>
                <td>53.5</td>
                <td><strong>55.2</strong></td>
                <td>+1.7</td>
              </tr>
              <tr>
                <td></td>
                <td>SQuAD <small>(EM)</small></td>
                <td>75.1</td>
                <td><strong>75.8</strong></td>
                <td>+0.7</td>
              </tr>
              <tr class="hruled">
                <td>Commonsense</td>
                <td>CommonsenseQA <small>(MC)</small></td>
                <td>33.5</td>
                <td><strong>53.8</strong></td>
                <td>+20.3</td>
              </tr>
              <tr>
                <td></td>
                <td>COPA <small>(MC)</small></td>
                <td>77.0</td>
                <td><strong>85.8</strong></td>
                <td>+8.8</td>
              </tr>
              <tr>
                <td></td>
                <td>PIQA <small>(MC)</small></td>
                <td>55.2</td>
                <td><strong>59.8</strong></td>
                <td>+4.6</td>
              </tr>
              <tr>
                <td></td>
                <td>Winograd <small>(MC)</small></td>
                <td>50.4</td>
                <td><strong>53.1</strong></td>
                <td>+2.7</td>
              </tr>
              <tr>
                <td></td>
                <td>Winogrande <small>(MC)</small></td>
                <td>47.3</td>
                <td><strong>52.6</strong></td>
                <td>+5.3</td>
              </tr>
              <tr class="hruled">
                <td>Language Understanding</td>
                <td>HellaSwag <small>(MC)</small></td>
                <td>29.7</td>
                <td><strong>33.7</strong></td>
                <td>+4.0</td>
              </tr>
              <tr>
                <td></td>
                <td>LAMBADA <small>(EM)</small></td>
                <td><strong>77.0</strong></td>
                <td>70.6</td>
                <td>&minus;6.4</td>
              </tr>
              <tr>
                <td></td>
                <td>Language Identification <small>(EM)</small></td>
                <td>8.8</td>
                <td><strong>9.0</strong></td>
                <td>+0.2</td>
              </tr>
              <tr class="hruled">
                <td>String Manipulation</td>
                <td>CS Algorithms <small>(EM)</small></td>
                <td>46.1</td>
                <td><strong>48.6</strong></td>
                <td>+2.5</td>
              </tr>
              <tr>
                <td></td>
                <td>CUTE <small>(EM)</small></td>
                <td>31.3</td>
                <td><strong>32.6</strong></td>
                <td>+1.3</td>
              </tr>
              <tr>
                <td></td>
                <td>Dyck-Languages <small>(EM)</small></td>
                <td><strong>15.9</strong></td>
                <td>14.2</td>
                <td>&minus;1.7</td>
              </tr>
            </tbody>
            <tfoot>
              <tr>
                <th>Average</th>
                <td></td>
                <td>39.8</td>
                <td><strong>43.8</strong></td>
                <td>+4.0</td>
              </tr>
            </tfoot>
          </table>
          </p>
          <p>
            Overall, SuperBPE provides a remarkable boost to both encoding efficiency and downstream performance to yield better language models. It replaces BPE tokenizers without requiring any other modifications to the architecture or training framework, making it a compelling alternative that seamlessly integrates with modern language model ecosystems.
          </p>
          <p>
            If you made it this far, we encourage you to read <a href="https://arxiv.org/pdf/2503.13423">our paper</a> for lots more experiments, discussion, and analysis!
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@misc{liu-etal-2025-superbpe,
      title={SuperBPE: Space Travel for Language Models},
      author={Alisa Liu and Jonathan Hayase and Valentin Hofmann and Sewoong Oh and Noah A. Smith and Yejin Choi},
      year={2025},
      eprint={2503.13423},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.13423},
}</code></pre>
          </div>
        </div>
      </div>
    </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://advtok.github.io/">Adversarial Tokenization project page</a>.
            The playground is based on <a href="https://huggingface.co/spaces/Xenova/the-tokenizer-playground/">Xenova/the-tokenizer-playground</a>.
            This website is licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.
            You are free to borrow the <a href="https://github.com/superbpe/superbpe.github.io">source code</a> of this website, we just ask that you remove the analystics code in the header and link back to this page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script type="module">
  import { initialize } from "https://cdn.jsdelivr.net/npm/@open-iframe-resizer/core@latest/dist/index.js";
  initialize({}, "#playgroundframe");
  initialize({targetElementSelector: "svg.mpld3-figure"}, "#plotframe");
</script>

</body>
</html>
