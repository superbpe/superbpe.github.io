<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZDNTVNBZY9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-ZDNTVNBZY9');
  </script>

  <meta charset="utf-8">
  <meta name="description"
        content="SuperBPE: Space Travel for Language Models">
  <meta name="keywords" content="superbpe superword tokenization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SuperBPE: Space Travel for Language Models</title>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Mono:wght@100..900&family=Noto+Sans:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@iframe-resizer/parent@5.3.3"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
</head>
<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SuperBPE: Space Travel for Language Models</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">*<a href="https://alisawuffles.github.io/">Alisa Liu</a><sup>&hearts;&#65038;&spades;&#65038;</sup>,</span>
            <span class="author-block">*<a href="https://jon.jon.ke/">Jonathan Hayase</a><sup>&hearts;&#65038;</sup>,</span>
            <span class="author-block"><a href="https://valentinhofmann.github.io/">Valentin Hofmann</a><sup>&diams;&#65038;&hearts;&#65038;</sup>,</span>
            <span class="author-block"><a href="https://homes.cs.washington.edu/~sewoong/">Sewoong Oh</a><sup>&hearts;&#65038;</sup>,</span>
            <span class="author-block"><a href="https://nasmith.github.io/">Noah A. Smith</a><sup>&hearts;&#65038;&diams;&#65038;</sup>,</span>
            <span class="author-block"><a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a><sup>&spades;&#65038;</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>&hearts;&#65038;</sup>University of Washington,</span>
            <span class="author-block"><sup>&spades;&#65038;</sup>NVIDIA</span>,
            <span class="author-block"><sup>&diams;&#65038;</sup>Allen Institute for AI</span>,
            <span class="eql-cntrb">*Equal contribution</span>
          </div>
        </div>
      </div>
      
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <span class="link-block">
              <a href="https://arxiv.org/pdf/2503.13423" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://arxiv.org/abs/2503.13423" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                <span>arXiv</span>
              </a>
            </span>
            <!-- Code Link. -->
            <span class="link-block">
              <a href="coming-soon.txt" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://huggingface.co/collections/UW/superbpe-67db2338062faa07c7473ffa" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-cloud-download-alt"></i></span>
                <span>HuggingFace</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="tldr">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths">
          <!-- TL;DR Section -->
        <div class="content is-size-5">
          <em><strong>TL;DR:</strong> We introduce a family of superword tokenizers that encode the same text using up to 33% fewer tokens than a BPE tokenizer of the same size. 8B models trained with our tokenizer are not only more efficient during inference, but also outperform the baseline on a large suite of downstream tasks, including +8.2% on MMLU.</em>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="playground">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="content">
          <iframe src="https://jhayase-superbpe-tokenizer-playground.static.hf.space"
                  frameborder="0"
            width="100%"
            id="playgroundframe"></iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="intro">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths">
        <div class="content">
          <p>
            Tokenizers are the interface through which language models interact with the world. Beginning from a blank slate, they learn the shape and form of language as sequences of tokens, becoming ever more capable. But in the end, the tokenizer will still govern the mapping between text and computation. Today, tokenization universally occurs at the level of subwords, meaning that tokens are parts of words (including complete words), but cannot bridge whitespace. Historically, subword tokenization was meant to combine the strengths of word-level tokenization, which cannot easily handle novel words, and byte-level tokenization, which can represent arbitrary text but is much less efficient.
          </p>
          <p>
            In the era of transformer language models, tokenization is done at the level of subwords, meaning that tokens are <em>parts</em> of words (including complete words), but cannot bridge whitespace. Historically, subword tokenization was meant to combine the strengths of <em>word-level tokenization</em>, which cannot easily handle novel words, and <em>byte-level tokenization</em>, which can represent arbitrary text but is much less efficient.
          </p>
          <p>
            But for modern language models, does it really make sense to limit tokens to parts of words? Whitespace is not a consistent delimiter of meaning — multi-word expressions (<em>“by the way”</em>) function semantically as single units, and different languages vary in the number of words needed to express a concept (<em>“spacesuit helmet”</em> is <em>“Raumanzughelm”</em> in German). At the extreme, <strong>languages such as Chinese do not use whitespace at all</strong>. Tokens in these languages span multiple words and even <a href="https://x.com/suchenzang/status/1790171161512587424">entire sentences</a>, yet this has seemingly not hindered LMs from learning these languages.
          </p>
          <p>
            We extend tokenization beyond subwords by introducing <strong>SuperBPE</strong>, an algorithm that produces tokenizers including both subword and “superword” tokens. As background, the subword restriction in BPE is enforced in a step called pretokenization, which splits the training text on whitespace to prevent common word sequences from becoming single tokens. SuperBPE modifies BPE by adding a simple pretokenization curriculum: the tokenizer first learns subwords by using pretokenization, and then lifts this restriction to transition to learning superwords.
          </p>
          <div class="is-flex is-horizontal-center">
            <figure class='image'>
                <img
                  src="static/images/fig1.svg"
                  alt="Plot with vocabulary size on the x-axis and bytes per token on the y-axis. SuperBPE outperforms both variants of BPE." />
                <figcaption>SuperBPE encodes text more efficiently than BPE and the gap grows with vocabulary size!</figcaption>
            </figure>
          </div>
          <p>
            We find that SuperBPE dramatically improves encoding efficiency over BPE, meaning that it segments the same piece of text into fewer tokens. This is because BPE tokenizers quickly exhaust the set of “useful” words to add to the vocabulary and begin adding increasingly rare (sub)words, which manifest as <a href="https://arxiv.org/abs/2405.05417">“undertrained tokens”</a> like the famous <a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation"><tt>_SolidGoldMagikarp</tt></a>. In contrast, SuperBPE can instead add common word sequences like <tt>_fish_oil</tt> to its vocabulary. For instance, at a fixed vocabulary size of 200k, a SuperBPE tokenizer uses 33% fewer tokens than BPE to encode the same amount of text!
          </p>
          <p>
            What happens when we train models with superword tokenizers? In our experiments, we pretrain 8B models from scratch, fixing everything about the model architecture and training setup and varying only the algorithm for learning the vocabulary. We find that <strong>models trained with SuperBPE tokenizers are consistently better</strong> — our best model achieves a <strong>+4.0% absolute improvement on average over 30 downstream tasks</strong> over the BPE baseline, winning on 25/30 of the individual tasks (including +8.2% on MMLU), <strong>while also being 27% more efficient at inference time.</strong>
          </p>
          <p>
            <div class="is-flex is-horizontal-center">
              <table class="table is-hoverable" id="resulttab">
                <thead>
                  <tr>
                    <th>Category</th>
                    <th>Task</th>
                    <th>BPE</th>
                    <th>SuperBPE</th>
                    <th>&Delta;</th>
                  </tr>
                </thead>
                <tbody>
                  <tr class="hruled">
                    <td>Knowledge</td>
                    <td>ARC-Easy <small>(MC)</small></td>
                    <td>46.6</td>
                <td><strong>67.1</strong></td>
                    <td>+20.5</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>ARC-Challenge <small>(MC)</small></td>
                    <td>35.1</td>
                    <td><strong>50.6</strong></td>
                    <td>+15.5</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>Jeopardy <small>(MC)</small></td>
                    <td><strong>42.1</strong></td>
                    <td>41.8</td>
                    <td>&minus;0.3</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>MMLU <small>(MC)</small></td>
                    <td>36.5</td>
                    <td><strong>44.7</strong></td>
                    <td>+8.2</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>OpenbookQA <small>(MC)</small></td>
                    <td>33.2</td>
                    <td><strong>54.4</strong></td>
                    <td>+21.2</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>TriviaQA <small>(EM)</small></td>
                    <td>60.6</td>
                    <td><strong>61.3</strong></td>
                    <td>+0.7</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>WikidataQA <small>(EM)</small></td>
                    <td>69.7</td>
                    <td><strong>70.9</strong></td>
                    <td>+1.2</td>
                  </tr>
                  <tr class="hruled">
                    <td>Math &amp; Reasoning</td>
                    <td>Arithmetic <small>(EM)</small></td>
                    <td>54.8</td>
                    <td><strong>59.3</strong></td>
                    <td>+4.5</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>GSM8K <small>(EM)</small></td>
                    <td>6.4</td>
                    <td><strong>6.7</strong></td>
                    <td>+0.3</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>LSAT-AR <small>(MC)</small></td>
                    <td>21.3</td>
                    <td><strong>23.0</strong></td>
                    <td>+1.7</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>Operators <small>(EM)</small></td>
                    <td><strong>35.5</strong></td>
                    <td>33.6</td>
                    <td>&minus;1.9</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>Repeat-Copy-Logic <small>(EM)</small></td>
                    <td>3.1</td>
                    <td><strong>6.2</strong></td>
                    <td>+3.1</td>
                  </tr>
                  <tr class="hruled">
                    <td>Coding</td>
                    <td>HumanEval <small>(pass@10)</small></td>
                    <td><strong>15.9</strong></td>
                    <td>13.4</td>
                    <td>&minus;2.5</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>MBPP <small>(pass@10)</small></td>
                    <td>27.5</td>
                    <td><strong>28.3</strong></td>
                    <td>+0.8</td>
                  </tr>
                  <tr class="hruled">
                    <td>Reading Comprehension</td>
                    <td>BoolQ <small>(MC)</small></td>
                    <td>59.7</td>
                    <td><strong>64.6</strong></td>
                    <td>+4.9</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>CoQA <small>(EM)</small></td>
                    <td>12.6</td>
                    <td><strong>13.2</strong></td>
                    <td>+0.6</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>DROP <small>(EM)</small></td>
                    <td>31.3</td>
                    <td><strong>31.4</strong></td>
                    <td>+0.1</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>HotpotQA <small>(EM)</small></td>
                    <td>53.5</td>
                    <td><strong>55.2</strong></td>
                    <td>+1.7</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>SQuAD <small>(EM)</small></td>
                    <td>75.1</td>
                    <td><strong>75.8</strong></td>
                    <td>+0.7</td>
                  </tr>
                  <tr class="hruled">
                    <td>Commonsense</td>
                    <td>CommonsenseQA <small>(MC)</small></td>
                    <td>33.5</td>
                    <td><strong>53.8</strong></td>
                    <td>+20.3</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>COPA <small>(MC)</small></td>
                    <td>77.0</td>
                    <td><strong>85.8</strong></td>
                    <td>+8.8</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>PIQA <small>(MC)</small></td>
                    <td>55.2</td>
                    <td><strong>59.8</strong></td>
                    <td>+4.6</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>Winograd <small>(MC)</small></td>
                    <td>50.4</td>
                    <td><strong>53.1</strong></td>
                    <td>+2.7</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>Winogrande <small>(MC)</small></td>
                    <td>47.3</td>
                    <td><strong>52.6</strong></td>
                    <td>+5.3</td>
                  </tr>
                  <tr class="hruled">
                    <td>Language Understanding</td>
                    <td>HellaSwag <small>(MC)</small></td>
                    <td>29.7</td>
                    <td><strong>33.7</strong></td>
                    <td>+4.0</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>LAMBADA <small>(EM)</small></td>
                    <td><strong>77.0</strong></td>
                    <td>70.6</td>
                    <td>&minus;6.4</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>Language Identification <small>(EM)</small></td>
                    <td>8.8</td>
                    <td><strong>9.0</strong></td>
                    <td>+0.2</td>
                  </tr>
                  <tr class="hruled">
                    <td>String Manipulation</td>
                    <td>CS Algorithms <small>(EM)</small></td>
                    <td>46.1</td>
                    <td><strong>48.6</strong></td>
                    <td>+2.5</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>CUTE <small>(EM)</small></td>
                    <td>31.3</td>
                    <td><strong>32.6</strong></td>
                    <td>+1.3</td>
                  </tr>
                  <tr>
                    <td></td>
                    <td>Dyck-Languages <small>(EM)</small></td>
                    <td><strong>15.9</strong></td>
                    <td>14.2</td>
                    <td>&minus;1.7</td>
                  </tr>
                </tbody>
                <tfoot>
                  <tr>
                    <th>Average</th>
                    <td></td>
                    <td>39.8</td>
                    <td><strong>43.8</strong></td>
                    <td>+4.0</td>
                  </tr>
                </tfoot>
              </table>
            </div>
          </p>
          <p>
            We also find that SuperBPE distributes difficulty more uniformly over tokens, overfitting less to extremely common and easy-to-predict words while also achieving much lower loss on the hardest tokens. This makes sense from a qualitative linguistic analysis — superword tokens often consist of multi-word expressions (<em>by accident, depend on, of course</em>) that function semantically as single units. The individual words in these expressions are often semantically vacuous and have little variation in context. Under BPE these correspond to extremely low-loss tokens, while they are merged into larger superword tokens under SuperBPE.
          </p>
          <div class="is-flex is-horizontal-center">
            <figure class='image'>
              <img
                src="static/images/log_loss_hist.svg"
                alt="Plot with vocabulary size on the x-axis and bytes per token on the y-axis. SuperBPE outperforms both variants of BPE." />
              <figcaption>SuperBPE has fewer tokens with very high and very low normalized loss!</figcaption>
            </figure>
          </div>
          <p>
            Together, these findings suggest that SuperBPE provides a better representation of the text for learning language over, giving a remarkable boost to both encoding efficiency and downstream performance. SuperBPE replaces BPE tokenizers without requiring any other modifications to the architecture or training framework, making it a compelling alternative that seamlessly integrates with modern language model ecosystems.
            You can run our models right now using <a href="https://huggingface.co/collections/UW/superbpe-67db2338062faa07c7473ffa">HuggingFace Transformers</a> and <a href="https://docs.vllm.ai/en/latest/">vLLM</a>!
          </p>
          <p>
            If you made it this far, we encourage you to read <a href="https://arxiv.org/pdf/2503.13423">our paper</a> for lots more experiments, discussion, and analysis!
          </p>
          <p>
            P.S. This blog post was 896 tokens when encoded by BPE, and 666 tokens when encoded by SuperBPE.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="content">
          <h2 class="title">BibTeX</h2>
          <pre><code>@misc{liu-etal-2025-superbpe,
      title={SuperBPE: Space Travel for Language Models},
      author={Alisa Liu and Jonathan Hayase and Valentin Hofmann and Sewoong Oh and Noah A. Smith and Yejin Choi},
      year={2025},
      eprint={2503.13423},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.13423},
}</code></pre>
          </div>
        </div>
      </div>
    </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://advtok.github.io/">Adversarial Tokenization project page</a>.
            The playground is based on <a href="https://huggingface.co/spaces/Xenova/the-tokenizer-playground/">Xenova/the-tokenizer-playground</a>.
            This website is licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.
            You are free to borrow the <a href="https://github.com/superbpe/superbpe.github.io">source code</a> of this website, we just ask that you remove the analystics code in the header and link back to this page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script type="module">
  import { initialize } from "https://cdn.jsdelivr.net/npm/@open-iframe-resizer/core@latest/dist/index.js";
  initialize({}, "#playgroundframe");
  initialize({targetElementSelector: "svg.mpld3-figure"}, "#plotframe");
</script>

</body>
</html>
